import sys
import re
import json
import tarfile
import logging
from contextlib import closing
from pathlib import Path

from tqdm.contrib.concurrent import process_map
from tqdm import tqdm
import validators
from tld import get_tld
# from mem_top import mem_top

from tokenizers.extract_javascript import getTokens
from classes.file import File
from classes.block import Block
from classes.token import Token
from util import attempt_decode

ESPRIMA_FILE_EXTENSIONS = [".js", ".jsx"]
FILE_EXTENSIONS = ESPRIMA_FILE_EXTENSIONS + [".ts", ".tsx"]

COMMENT_RE_PATTERN = r"\/\*[\s\S]*?\*\/|([^\\:]|^)\/\/.*|<!--[\s\S]*?-->$"
SUSPICIOUS_FUNCTIONS = [
  "eval",
  "atob",
  # child_process
  # "exec", # removed because it's also used in regexes a lot...
  "execSync",
  "spawn",
  # process
  "getuid",
  # vm
  "runInThisContext",
  "runInNewContext",
  "runInContext"
]
SUSPICIOUS_STRINGS = [
  ".ssh/",
  ".gpg/",
  ".gpg2",
  ".bashrc",
  ".bash_profile",
  "rm -rf /",
  "/bin/sh",
  "/bin/bash",
  "/etc/passwd",
  "/etc/shadow",
  "child_process",
  "pastebin",
  "whoami"
]
SUSPICIOUS_STRING_REGEX = "|".join([re.escape(s) for s in SUSPICIOUS_STRINGS]) + r"|^(\\x[0-9a-fA-F]{2}){5,}$"
# Matches e.g.
# - Buffer.from([1, 2, 3])
# - Buffer.from(var, "base64")
# - Buffer.from(var, "hex")
# - Buffer.from("")
SUSPICIOUS_BUFFER_REGEX = r".*Buffer(?:\.from)?\([a-zA-Z0-9\-\"']+ ?, ?[\"'](?:base64|hex)[\"']\).*|.*Buffer(?:\.from)?\(\[(?:(:?0x[a-eA-E0-9]{2}|\d),? ?)+\]\).*"


logger = logging.getLogger(__name__)


def detect_strings(code_strings):
  # Takes a list of strings extracted from a file
  matches = []
  web_addresses = []
  # Look for naive suspiciuous strings
  for c in code_strings:
    if re.search(SUSPICIOUS_STRING_REGEX, c):
      matches.append(c)
    if len(c) > 1 and (validators.ipv4(c) or validators.ipv6(c)):
      web_addresses.append(c)
    elif validators.domain(c) and get_tld("http://{}".format(c), fail_silently=True) != None:
      # web_addresses.append(c)
      pass

  return matches, web_addresses


def detect_functions(identifiers):
  matches = []
  for i in identifiers:
    if i in SUSPICIOUS_FUNCTIONS:
      matches.append(i)
  return matches


def process_tarball(tarball, path):
  name = None
  version = None
  skip = False

  suspicious_strings = []
  suspicious_hexes = []
  suspicious_functions = []
  suspicious_web_addresses = []

  for member in tarball.getmembers():
    if skip:
      continue

    if not member.isfile() or "/node_modules/" in member.name or member.name.startswith("node_modules/"):
      continue

    # Don't process files >1MB (these probably aren't source code)
    if member.size > 1000000:
      continue

    if member.name == 'package/package.json' or member.name == "package.json":
      with tarball.extractfile(member) as f:
        raw_json = f.read()
        try:
          parsed_json = json.loads(attempt_decode(raw_json))
          name = parsed_json["name"]
          version = parsed_json["version"]
          # Check if we've already processed this package
          output_path = Path("logs/strings/{}.log".format(name.replace("/", "--")))
          if output_path.exists():
            skip = True
            break
        except:
          logger.error("Failed to get name of {}".format(path))
          break
    
    else:
      with tarball.extractfile(member) as f:
        file_bytes = f.read()

      if member.name.startswith("package/"):
        file_path = member.name.replace("package/", "", 1) 
      else:
        file_path = member.name

      if any(member.name.lower().endswith(ext) for ext in FILE_EXTENSIONS):
        file_contents = None
        try:
          file_contents = attempt_decode(file_bytes)
        except:
          logger.warning("Could not extract {} from {}".format(member.name, path))
        if file_contents != None:
          # Remove comments
          file_contents = re.sub(COMMENT_RE_PATTERN, "", file_contents)

          # First, process without lexical analysis
          curr_suspicious_functions = re.findall(SUSPICIOUS_BUFFER_REGEX, file_contents)

          # If we can parse this file type, extract strings and hex-encoded numbers
          if any(member.name.lower().endswith(ext) for ext in ESPRIMA_FILE_EXTENSIONS):
            strings, hexes, identifiers = None, None, None
            try:
              strings, hexes, identifiers = getTokens(file_contents)
            except:
              logger.warning("Failed to get tokens in {} ({})".format(file_path, name))

            if strings != None and hexes != None and identifiers != None:
              curr_suspicious_strings, curr_web_addresses = detect_strings(strings)
              curr_suspicious_functions.extend(detect_functions(identifiers))

              if len(curr_suspicious_strings) > 0:
                suspicious_strings.append((curr_suspicious_strings, file_path))
              if len(curr_web_addresses) > 0:
                suspicious_web_addresses.append((curr_web_addresses, file_path))
              if len(hexes) > 0:
                suspicious_hexes.append((hexes, file_path))
              if len(curr_suspicious_functions) > 0:
                suspicious_functions.append((curr_suspicious_functions, file_path))

  if name == None:
    logger.error("Failed to get name of {}".format(path))
    return

  if suspicious_functions or suspicious_strings or suspicious_hexes and not skip:
    output_path = Path("logs/strings/{}.log".format(name.replace("/", "--")))
    with open(output_path, "w") as f:
      for (fs, file_path) in suspicious_functions:
        for func in fs:
          f.write("Function {} in {}\n".format(func, file_path))

      for (strings, file_path) in suspicious_strings:
        for s in strings:
          f.write("String {} in {}\n".format(s, file_path))

      for (addresses, file_path) in suspicious_web_addresses:
        for a in addresses:
          f.write("Web address {} in {}\n".format(a, file_path))

      for (hexes, file_path) in suspicious_hexes:
        f.write("{} hex-encoded ints in {}\n".format(len(hexes), file_path))


def process_project_strings(project_path):
  try:
    # Open tarball with transparent compression
    # (supports gzip, bz2 and lzma)
    with closing(tarfile.open(project_path, "r:*")) as tarball:
      process_tarball(tarball, project_path)
  except tarfile.ReadError:
    logger.error("Failed to open {}".format(project_path))
    return project_path
