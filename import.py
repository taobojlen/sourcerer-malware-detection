import argparse
import sys
import csv
import logging
from pathlib import Path, PurePath
from multiprocessing import Pool

from tqdm import tqdm

from db import create_tables
from tokenizers.tokenizer import process_project, process_malicious_project


if __name__ == "__main__":
  parser = argparse.ArgumentParser()
  parser.add_argument('--projects', help="list of project paths to import")
  parser.add_argument('--malicious', action='store_true', help="mark imported projects as malicious")

  args = parser.parse_args()
  if args.projects == None:
    print("Missing --projects flag; exiting.")
    sys.exit(1)

  create_tables()
  
  log_dir = Path("logs")
  log_dir.mkdir(parents=True, exist_ok=True)
  log_path = log_dir / PurePath("output.log")
  logging.basicConfig(
    level=logging.DEBUG,
    filename=log_path,
    format="%(asctime)s %(levelname)-8s %(message)s",
    datefmt="%Y-%m-%dT%H:%M:%S"
  )
  logger = logging.getLogger(__name__)

  if args.malicious:
    with open(args.projects, "r") as f:
      reader = csv.reader(f)
      # list of (project_path, [malicious_file])
      project_paths = [r for r in reader]
      processing_function = process_malicious_project
  else:
    with open(args.projects, "r") as f:
      # list of project paths
      project_paths = [p.strip() for p in f.readlines()]
      processing_function = process_project

  # Process everything
  errors = []
  with Pool(processes=12) as p:
    with tqdm(total=len(project_paths)) as pbar:
      for e in p.imap_unordered(processing_function, project_paths):
        pbar.update()
        errors.append(e)
  # for idx, p in enumerate(tqdm(project_paths)):
  #   error = process_project(p)
  #   errors.append(error)

  errors_path = log_dir / PurePath("errors.txt")
  with open(errors_path, "w+") as f:
    for e in errors:
      if e != None:
        f.write("{}\n".format(e))
